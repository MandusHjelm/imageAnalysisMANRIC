{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! git clone https://github.com/experiencor/raccoon_dataset.git\n",
    "import pycocotools\n",
    "import sys\n",
    "import os\n",
    "\n",
    "#os.chdir(\"./tools\")\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "#!export OMP_NUM_THREADS=1\n",
    "\n",
    "## Insert data path\n",
    "#Mandus \n",
    "path_to_data_file = \"../../Data/\"\n",
    "path_to_csv = '../Data/dataFrameMerged.csv'\n",
    "\n",
    "# Eric \n",
    "#path_to_data_file = \"../../data/\"\n",
    "#path_to_csv = '../data/dataFrameMerged.csv'\n",
    "\n",
    "dataFrame = pd.read_csv(path_to_csv)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image</th>\n",
       "      <th>odometer_type</th>\n",
       "      <th>mileage</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>00000002-PHOTO-2020-11-20-11-21-22.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>244362.0</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>odometer</td>\n",
       "      <td>249.00</td>\n",
       "      <td>399.21</td>\n",
       "      <td>452.90</td>\n",
       "      <td>456.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>00000003-PHOTO-2020-11-20-11-21-23.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>64750.0</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>odometer</td>\n",
       "      <td>300.00</td>\n",
       "      <td>413.31</td>\n",
       "      <td>420.60</td>\n",
       "      <td>485.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>00000004-PHOTO-2020-11-20-11-21-25.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>159073.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>768</td>\n",
       "      <td>odometer</td>\n",
       "      <td>461.27</td>\n",
       "      <td>324.00</td>\n",
       "      <td>931.55</td>\n",
       "      <td>532.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>00000005-PHOTO-2020-11-20-11-21-26.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>18613.0</td>\n",
       "      <td>576</td>\n",
       "      <td>1024</td>\n",
       "      <td>odometer</td>\n",
       "      <td>216.78</td>\n",
       "      <td>582.97</td>\n",
       "      <td>333.70</td>\n",
       "      <td>626.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>00000006-PHOTO-2020-11-20-11-21-26.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>35376.0</td>\n",
       "      <td>768</td>\n",
       "      <td>1024</td>\n",
       "      <td>odometer</td>\n",
       "      <td>230.34</td>\n",
       "      <td>504.17</td>\n",
       "      <td>474.49</td>\n",
       "      <td>671.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>2384</td>\n",
       "      <td>00006473-PHOTO-2020-12-29-21-24-53.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>118818.0</td>\n",
       "      <td>901</td>\n",
       "      <td>1600</td>\n",
       "      <td>odometer</td>\n",
       "      <td>244.93</td>\n",
       "      <td>653.80</td>\n",
       "      <td>632.40</td>\n",
       "      <td>846.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>2385</td>\n",
       "      <td>00006474-PHOTO-2020-12-29-21-31-54.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>27203.0</td>\n",
       "      <td>747</td>\n",
       "      <td>1328</td>\n",
       "      <td>odometer</td>\n",
       "      <td>281.20</td>\n",
       "      <td>703.19</td>\n",
       "      <td>467.50</td>\n",
       "      <td>747.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>2386</td>\n",
       "      <td>00006496-PHOTO-2020-12-29-21-34-33.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>17611.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>1600</td>\n",
       "      <td>odometer</td>\n",
       "      <td>475.40</td>\n",
       "      <td>951.10</td>\n",
       "      <td>696.10</td>\n",
       "      <td>1032.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2387</td>\n",
       "      <td>00006499-PHOTO-2020-12-29-21-58-07.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>30076.0</td>\n",
       "      <td>738</td>\n",
       "      <td>1600</td>\n",
       "      <td>odometer</td>\n",
       "      <td>249.96</td>\n",
       "      <td>803.69</td>\n",
       "      <td>473.15</td>\n",
       "      <td>898.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2388</td>\n",
       "      <td>00006508-PHOTO-2020-12-29-22-17-11.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>43.6</td>\n",
       "      <td>1200</td>\n",
       "      <td>1600</td>\n",
       "      <td>odometer</td>\n",
       "      <td>120.90</td>\n",
       "      <td>350.60</td>\n",
       "      <td>821.10</td>\n",
       "      <td>838.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2389 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                   image  odometer_type  \\\n",
       "0              0  00000002-PHOTO-2020-11-20-11-21-22.jpg              0   \n",
       "1              1  00000003-PHOTO-2020-11-20-11-21-23.jpg              1   \n",
       "2              2  00000004-PHOTO-2020-11-20-11-21-25.jpg              1   \n",
       "3              3  00000005-PHOTO-2020-11-20-11-21-26.jpg              0   \n",
       "4              4  00000006-PHOTO-2020-11-20-11-21-26.jpg              0   \n",
       "...          ...                                     ...            ...   \n",
       "2384        2384  00006473-PHOTO-2020-12-29-21-24-53.jpg              1   \n",
       "2385        2385  00006474-PHOTO-2020-12-29-21-31-54.jpg              0   \n",
       "2386        2386  00006496-PHOTO-2020-12-29-21-34-33.jpg              0   \n",
       "2387        2387  00006499-PHOTO-2020-12-29-21-58-07.jpg              1   \n",
       "2388        2388  00006508-PHOTO-2020-12-29-22-17-11.jpg              1   \n",
       "\n",
       "       mileage  width  height     class    xmin    ymin    xmax     ymax  \n",
       "0     244362.0    768    1024  odometer  249.00  399.21  452.90   456.74  \n",
       "1      64750.0    768    1024  odometer  300.00  413.31  420.60   485.75  \n",
       "2     159073.0   1024     768  odometer  461.27  324.00  931.55   532.14  \n",
       "3      18613.0    576    1024  odometer  216.78  582.97  333.70   626.14  \n",
       "4      35376.0    768    1024  odometer  230.34  504.17  474.49   671.03  \n",
       "...        ...    ...     ...       ...     ...     ...     ...      ...  \n",
       "2384  118818.0    901    1600  odometer  244.93  653.80  632.40   846.00  \n",
       "2385   27203.0    747    1328  odometer  281.20  703.19  467.50   747.70  \n",
       "2386   17611.0   1200    1600  odometer  475.40  951.10  696.10  1032.55  \n",
       "2387   30076.0    738    1600  odometer  249.96  803.69  473.15   898.84  \n",
       "2388      43.6   1200    1600  odometer  120.90  350.60  821.10   838.40  \n",
       "\n",
       "[2389 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filelist(root, file_type):\n",
    "    \"\"\"Returns a fully-qualified list of filenames under root directory\"\"\"\n",
    "    return [os.path.join(directory_path, f) for directory_path, directory_name, \n",
    "            files in os.walk(root) for f in files if f.endswith(file_type)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(img,idx):\n",
    "    label = dataFrame[\"odometer_type\"][idx]\n",
    "    \n",
    "    return label\n",
    "    \n",
    "def read_odometer_boxes(path_data_file, idx):\n",
    "    boxes = []\n",
    "    \n",
    "    ymin = dataFrame[\"ymin\"][idx]\n",
    "    ymax = dataFrame[\"ymax\"][idx]\n",
    "    xmin = dataFrame[\"xmin\"][idx]\n",
    "    xmax = dataFrame[\"xmax\"][idx]\n",
    "    \n",
    "    boxes.append([xmin, ymin, xmax, ymax])\n",
    "            \n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrodoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, data_file, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.imgs = sorted(os.listdir(os.path.join(root, \"images\")))\n",
    "        self.data_file = data_file\n",
    "        #self.path_to_data_file = data_file\n",
    "    def __getitem__(self, idx):\n",
    "      # load images and bounding boxes\n",
    "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        label = get_labels(self.imgs,idx)\n",
    "        labels = torch.tensor((label,), dtype=torch.int64)\n",
    "        \n",
    "        box_list = read_odometer_boxes(self.data_file,idx)\n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        \n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "        \n",
    "        iscrowd = torch.zeros((2,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        return img, target\n",
    "    def __len__(self):\n",
    "         return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TrodoDataset(root = path_to_data_file,\n",
    "                         data_file= \"../data/dataFrameMerged.csv\")\n",
    "#dataset.__getitem__(5)\n",
    "\n",
    "#for e in dataset:\n",
    "#    print(e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download and adjust the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model(num_classes):\n",
    "    # load an object detection model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    print(in_features)\n",
    "    # replace the pre-trained head with a new on\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "   # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "      # during training, randomly flip the training images\n",
    "      # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have: 2389 examples, 2189 are training and 200 testing\n"
     ]
    }
   ],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = TrodoDataset(root= path_to_data_file,\n",
    "                         data_file= \"../data/dataFrameMerged.csv\",\n",
    "                         transforms = get_transform(train=True))\n",
    "dataset_test = TrodoDataset(root= path_to_data_file,\n",
    "                         data_file= \"../data/dataFrameMerged.csv\",\n",
    "                              transforms = get_transform(train=False))\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-200])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-200:])\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=0,\n",
    "                                          collate_fn=utils.collate_fn)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=64,\n",
    "                                               shuffle=False, num_workers=0,\n",
    "                                               collate_fn=utils.collate_fn)\n",
    "\n",
    "\n",
    "print(\"We have: {} examples, {} are training and {} testing\".format(len(indices), len(dataset), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /Users/mandushjelm/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# our dataset has two classes only - digital or analog odometer\n",
    "num_classes = 2\n",
    "\n",
    "model = get_model(num_classes)\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=3,\n",
    "                                               gamma=0.1)\n",
    "#torch.set_num_threads(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch,\n",
    "                   print_freq=10)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=650x417 at 0x7FF35AF81390>,\n",
       " {'boxes': tensor([[ 81.,  88., 522., 408.]]),\n",
       "  'labels': tensor([1]),\n",
       "  'image_id': tensor([0]),\n",
       "  'area': tensor([141120.]),\n",
       "  'iscrowd': tensor([0])})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save model ###\n",
    "#time = date.time()\n",
    "#os.mkdir(\"models/pytorch_odometer_classifier/\")\n",
    "#torch.save(model.state_dict(), \"models/pytorch_odometer_classifier/model\" + time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Model ###\n",
    "\n",
    "##loaded_model = get_model(num_classes = 2)\n",
    "##loaded_model.load_state_dict(torch.load(models/pytorch_odometer_classifier/model\" + time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
